<<<<<<< HEAD
---
title: "Stat380_FinalProject_Hainley_Sepich"
author: "Joseph Sepich and Connor Hainley"
date: "2019-04-30"
output: 
  html_document:
    keep_md: yes
  html_notebook: default
---

# Front matter

```{r message = FALSE, warning = FALSE}
# always clean up R environment
rm(list = ls())
# load all packages here
library(mdsr) # book package of utilities
library(stringr) # utility package for strings
library(tidyr) # tidyverse utilities
library(lubridate) # date utility package
library(data.table) # using fread function
library(rvest) # web scraping package
library(readxl) # read execel files
library(readr)

# user defined functions
# readTables

# data
```
# Obtaining the data

Links to download data from BEA:

GDP by area:  https://apps.bea.gov/regional/downloadzip.cfm
GDP: https://www.bea.gov/data/gdp/gross-domestic-product
Homeland Security: https://www.dhs.gov/immigration-statistics/yearbook/2017


Codes to know:

* GDP in current dollars SAGDP2
* Compensation of Employees SAGDP4
* Real GDP in chained SAGDP9
* Per capita real GDP SAGDP10

## Compile GDP data into tables based on code

```{r}
# First read in all csv files into single data table
dataPath <- read_file('dataPath.txt')
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP2N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP2
nominalGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(nominalGDP)
write.csv(nominalGDP, file = paste0(dataPath,"SAGDP2.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP4N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP4
compensationGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(compensationGDP)
write.csv(compensationGDP, file = paste0(dataPath,"SAGDP4.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP9N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP9
realGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(realGDP)
write.csv(realGDP, file = paste0(dataPath,"SAGDP9.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP10N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP10
perCapitaGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(perCapitaGDP)
write.csv(perCapitaGDP, file = paste0(dataPath,"SAGDP10.csv"))
```
 
## Scraping Immigration statistics 
 
```{r}
# returns immigration table found on the page of a specific url
readTable <- function(url) {
  table <- url %>%
            read_html() %>%
            html_nodes(xpath=paste0('/html/body/div[2]/section/div/div/div[2]/',
                                    'div/section/div/div/div/article/div[1]/',
                                    'div[2]/div/div/table')) %>%
            html_table()
  table <- table[[1]]
}
```

```{r}
# Started putting tables online in 2014, prior they are in csv for download.
# Use 2013, 2004 and scrape 2014-2017
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-4),"Immigration/")
```
```{r}
# Scrape data from 2014-2017
immigrants <- NA
immigrants <- data.frame(stringsAsFactors = FALSE)
year <- 2014
while (year <= 2017) {
  url <- paste0("https://www.dhs.gov/immigration-statistics/yearbook/",year,
                "/table22")
  if (year == 2014) {
    immigrants <- readTable(url)
  } else {
    immigrants[,as.character(year)] <- readTable(url)[,as.character(year)]
  }
  year <- year + 1
}
# Read in and add data from 8_ - 2013
# Table33
# 2103 table 22
files <- list.files(path = dataPath, pattern = ".(xls|xlxs)$")
data1 <- read_excel(paste0(dataPath,files[1]))
data2 <- read_excel(paste0(dataPath,files[2]))

data1 <- data1[1:(length(data1$`Table 22.`)-3),]
data1 <- data1[3:length(data1$`Table 22.`),]
data1[1,1] <- "State or Territory of Residence"

data2 <- data2 %>%
  filter(!is.na(`TABLE 33.`))
data2 <- data2[1:(length(data2$`TABLE 33.`)-2),]
data2 <- data2[2:length(data2$`TABLE 33.`),]
data2[1,1] <- data1[1,1]

colnames(data1) <- as.character(unlist(data1[1,]))
data1 <- data1[-1, ]
data1 <- data1 %>%
  select(-c("2012","2013"))

colnames(data2) <- as.character(unlist(data2[1,]))
data2 <- data2[-1, ]
data2 <- data2 %>%
  select(-c("2004"))

# Convert data types to numeric to match with data1
colsNum <- colnames(data2)
colsNum <- colsNum[2:length(colsNum)]
data2[colsNum] <- sapply(data2[colsNum],as.numeric)
colsNum <- colnames(immigrants)
colsNum <- colsNum[2:length(colsNum)]
immigrants[colsNum] <- sapply(immigrants[colsNum],function(x) gsub(",","",x))
immigrants[colsNum] <- sapply(immigrants[colsNum],as.numeric)

immigrants <- immigrants %>%
      left_join(data1, by = c("State or Territory of Residence"))
immigrants <- immigrants %>%
      left_join(data2, by = c("State or Territory of Residence"))
write.csv(immigrants, file = paste0(dataPath,"immigration.csv"))
```
 
## Read in tables
```{r eval = FALSE}
immigrants <- fread(file = paste0(dataPath,"immigration.csv"))
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-12),"GDP/")
nominalGDP <- fread(file = paste0(dataPath,"SAGDP2.csv"))
compensationGDP <- fread(file = paste0(dataPath,"SAGDP4.csv"))
realGDP <- fread(file = paste0(dataPath,"SAGDP9.csv"))
perCapitaGDP <- fread(file = paste0(dataPath,"SAGDP10.csv"))
```

## Join two data sets
```{r}
econData <- nominalGDP %>%
  rbind(compensationGDP) %>%
  rbind(realGDP) %>%
  rbind(perCapitaGDP) %>%
  filter(nchar(TableName) != 0)
# Name GDP years
names <- colnames(econData)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    econData[,paste0(names[i])] <- as.numeric(econData[,paste0(names[i])])
    names[i] <- paste0("GDP: ",names[i])
  }
}
colnames(econData) <- names
# Name immigation years
names <- colnames(immigrants)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    names[i] <- paste0("Immigrants: ",names[i])
  }
}
colnames(immigrants) <- names
# Change total name
immigrants[1,1] <- "United States*"
compiledData <- econData %>%
  left_join(immigrants, by = c("GeoName" = "State or Territory of Residence"))
```



# Simulating the Romer Growth Model












=======
---
title: "Stat380_FinalProject_Hainley_Sepich"
author: "Joseph Sepich and Connor Hainley"
date: "2019-04-30"
output: 
  html_document:
    keep_md: yes
  html_notebook: default
---

# Front matter

```{r message = FALSE, warning = FALSE}
# always clean up R environment
rm(list = ls())
# load all packages here
library(mdsr) # book package of utilities
library(stringr) # utility package for strings
library(tidyr) # tidyverse utilities
library(lubridate) # date utility package
library(data.table) # using fread function
library(rvest) # web scraping package
library(readxl) # read execel files
library(readr) # utilities

# user defined functions
# readTables

# data
```
# Obtaining the data

Links to download data from BEA:

GDP by area:  https://apps.bea.gov/regional/downloadzip.cfm
GDP: https://www.bea.gov/data/gdp/gross-domestic-product
Homeland Security: https://www.dhs.gov/immigration-statistics/yearbook/2017


Codes to know:

* GDP in current dollars SAGDP2
* Compensation of Employees SAGDP4
* Real GDP in chained SAGDP9
* Per capita real GDP SAGDP10

## Compile GDP data into tables based on code

```{r}
# First read in all csv files into single data table
dataPath <- read_file('dataPath.txt')
```
```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP2N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP2
nominalGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(nominalGDP)
write.csv(nominalGDP, file = paste0(dataPath,"SAGDP2.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP4N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP4
compensationGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(compensationGDP)
write.csv(compensationGDP, file = paste0(dataPath,"SAGDP4.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP9N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP9
realGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(realGDP)
write.csv(realGDP, file = paste0(dataPath,"SAGDP9.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP10N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP10
perCapitaGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(perCapitaGDP)
write.csv(perCapitaGDP, file = paste0(dataPath,"SAGDP10.csv"))
```
 
## Scraping Immigration statistics 
 
```{r}
# returns immigration table found on the page of a specific url
readTable <- function(url) {
  table <- url %>%
            read_html() %>%
            html_nodes(xpath=paste0('/html/body/div[2]/section/div/div/div[2]/',
                                    'div/section/div/div/div/article/div[1]/',
                                    'div[2]/div/div/table')) %>%
            html_table()
  table <- table[[1]]
}
```

```{r}
# Started putting tables online in 2014, prior they are in csv for download.
# Use 2013, 2004 and scrape 2014-2017
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-4),"Immigration/")
```
```{r}
# Scrape data from 2014-2017
immigrants <- NA
immigrants <- data.frame(stringsAsFactors = FALSE)
year <- 2014
while (year <= 2017) {
  url <- paste0("https://www.dhs.gov/immigration-statistics/yearbook/",year,
                "/table22")
  if (year == 2014) {
    immigrants <- readTable(url)
  } else {
    immigrants[,as.character(year)] <- readTable(url)[,as.character(year)]
  }
  year <- year + 1
}
# Read in and add data from 8_ - 2013
# Table33
# 2103 table 22
files <- list.files(path = dataPath, pattern = ".(xls|xlsx)$")
data1 <- read_excel(paste0(dataPath,files[1]))
data2 <- read_excel(paste0(dataPath,files[2]))

data1 <- data1[1:(length(data1$`Table 22.`)-3),]
data1 <- data1[3:length(data1$`Table 22.`),]
data1[1,1] <- "State or Territory of Residence"

data2 <- data2 %>%
  filter(!is.na(`TABLE 33.`))
data2 <- data2[1:(length(data2$`TABLE 33.`)-2),]
data2 <- data2[2:length(data2$`TABLE 33.`),]
data2[1,1] <- data1[1,1]

colnames(data1) <- as.character(unlist(data1[1,]))
data1 <- data1[-1, ]
data1 <- data1 %>%
  select(-c("2012","2013"))

colnames(data2) <- as.character(unlist(data2[1,]))
data2 <- data2[-1, ]
data2 <- data2 %>%
  select(-c("2004"))

# Convert data types to numeric to match with data1
colsNum <- colnames(data2)
colsNum <- colsNum[2:length(colsNum)]
data2[colsNum] <- sapply(data2[colsNum],as.numeric)
colsNum <- colnames(immigrants)
colsNum <- colsNum[2:length(colsNum)]
immigrants[colsNum] <- sapply(immigrants[colsNum],function(x) gsub(",","",x))
immigrants[colsNum] <- sapply(immigrants[colsNum],as.numeric)

immigrants <- immigrants %>%
      left_join(data1, by = c("State or Territory of Residence"))
immigrants <- immigrants %>%
      left_join(data2, by = c("State or Territory of Residence"))
write.csv(immigrants, file = paste0(dataPath,"immigration.csv"))
```
 
## Read in tables
```{r eval=FALSE}
immigrants <- fread(file = paste0(dataPath,"immigration.csv"))
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-12),"GDP/")
nominalGDP <- fread(file = paste0(dataPath,"SAGDP2.csv"))
compensationGDP <- fread(file = paste0(dataPath,"SAGDP4.csv"))
realGDP <- fread(file = paste0(dataPath,"SAGDP9.csv"))
perCapitaGDP <- fread(file = paste0(dataPath,"SAGDP10.csv"))
```

## Join two data sets
```{r}
econData <- nominalGDP %>%
  rbind(compensationGDP) %>%
  rbind(realGDP) %>%
  rbind(perCapitaGDP) %>%
  filter(nchar(TableName) != 0)
# Name GDP years
names <- colnames(econData)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    econData[,paste0(names[i])] <- as.numeric(econData[,paste0(names[i])])
    names[i] <- paste0("GDP: ",names[i])
  }
}
colnames(econData) <- names
# Name immigation years
names <- colnames(immigrants)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    names[i] <- paste0("Immigrants: ",names[i])
  }
}
colnames(immigrants) <- names
# Change total name
immigrants[1,1] <- "United States*"
compiledData <- econData %>%
  left_join(immigrants, by = c("GeoName" = "State or Territory of Residence"))
```



# Simulating the Romer Growth Model

```{r}
chooseCols <- function(x, regex) {
  cols <- grep(regex, names(x), value=TRUE)
  return(x[, cols])
}
```

```{r}
# Returns table of population in millions
createPopulationTable <- function() {
  # Divide real GDP by percapita
  real <- compiledData %>%
    filter(TableName == "SAGDP9N" & IndustryId == 1)
  per <- compiledData %>%
    filter(TableName == "SAGDP10N")
  real <- chooseCols(real, "^(GDP:|GeoName)")
  per <- chooseCols(per, "^(GDP:|GeoName)")
  pop <- real
  cols <- names(per)
  for (i in 2:length(cols)) {
    pop[,paste0(cols[i])] <- real[,paste0(cols[i])] / per[,paste0(cols[i])]
  }
  return(pop)
}
```

```{r}
# per capita GDP is tableName SAGDP10N
perCapitaGDP <- compiledData %>%
  filter(TableName == "SAGDP10N")
outputPerWorker <- chooseCols(perCapitaGDP, "^(GDP:|GeoName)")
head(outputPerWorker)
```

```{r}
# Romer growth parameters
beta <- 0.3
alpha <- 0.2
chi <- 0.04
# Population in millions
population <- createPopulationTable()
growth <- population
cols <- names(population)
colsGrowth <- gsub("GDP:","Growth:",cols)
for (i in 2:length(cols)) {
  growth[,paste0(colsGrowth[i])] <- (1 / (1 - beta)) * alpha * chi * population[,paste0(cols[i])]
}
growth <- chooseCols(growth, "^(Growth:|GeoName)")
head(growth)
```

```{r}
# Show graph of PerCapita and growth
years <- grep("[0-9]$", names(outputPerWorker), value=TRUE)
years <- as.numeric(gsub("GDP: ","",years))
totalper <- as.numeric((as.vector(outputPerWorker[1,c(2:22)])))
data <- data.frame(year = years, output = totalper)
data %>%
  ggplot(aes(x = year, y = output)) +
  geom_point()
```







>>>>>>> 4000d166d54f7c6a6eb3d8b927e0a61d070dcc39
