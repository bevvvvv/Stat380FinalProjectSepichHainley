
---
title: "Stat380_FinalProject_Hainley_Sepich"
author: "Joseph Sepich and Connor Hainley"
date: "2019-04-30"
output: 
  html_document:
    keep_md: yes
  html_notebook: default
---

# Front matter

```{r message = FALSE, warning = FALSE}
# always clean up R environment
rm(list = ls())
# load all packages here
library(mdsr) # book package of utilities
library(stringr) # utility package for strings
library(tidyr) # tidyverse utilities
library(lubridate) # date utility package
library(data.table) # using fread function
library(rvest) # web scraping package
library(readxl) # read execel files
library(readr) # utilities
library(tidyverse) #create visualization
library(usmap)

# user defined functions
# readTables

# data
```
# Obtaining the data

Links to download data from BEA:

GDP by area:  https://apps.bea.gov/regional/downloadzip.cfm
GDP: https://www.bea.gov/data/gdp/gross-domestic-product
Homeland Security: https://www.dhs.gov/immigration-statistics/yearbook/2017


Codes to know:

* GDP in current dollars SAGDP2
* Compensation of Employees SAGDP4
* Real GDP in chained SAGDP9
* Per capita real GDP SAGDP10

## Compile GDP data into tables based on code

```{r}
# First read in all csv files into single data table
dataPath <- read_file('dataPath.txt')
```
```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP2N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP2
nominalGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(nominalGDP)
write.csv(nominalGDP, file = paste0(dataPath,"SAGDP2.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP4N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP4
compensationGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(compensationGDP)
write.csv(compensationGDP, file = paste0(dataPath,"SAGDP4.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP9N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP9
realGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(realGDP)
write.csv(realGDP, file = paste0(dataPath,"SAGDP9.csv"))
```

```{r}
files <- list.files(path = dataPath,
                    pattern = "^SAGDP10N__ALL_AREAS_[0-9]*_[0-9]*.csv$")
# SAGDP10
perCapitaGDP <- fread(file = paste0(dataPath,files[1]), fill = TRUE)
head(perCapitaGDP)
write.csv(perCapitaGDP, file = paste0(dataPath,"SAGDP10.csv"))
```
 
## Scraping Immigration statistics 
 
```{r}
# returns immigration table found on the page of a specific url
readTable <- function(url) {
  table <- url %>%
            read_html() %>%
            html_nodes(xpath=paste0('/html/body/div[2]/section/div/div/div[2]/',
                                    'div/section/div/div/div/article/div[1]/',
                                    'div[2]/div/div/table')) %>%
            html_table()
  table <- table[[1]]
}
```

```{r}
# Started putting tables online in 2014, prior they are in csv for download.
# Use 2013, 2004 and scrape 2014-2017
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-4),"Immigration/")
```
```{r}
# Scrape data from 2014-2017
immigrants <- NA
immigrants <- data.frame(stringsAsFactors = FALSE)
year <- 2014
while (year <= 2017) {
  url <- paste0("https://www.dhs.gov/immigration-statistics/yearbook/",year,
                "/table22")
  if (year == 2014) {
    immigrants <- readTable(url)
  } else {
    immigrants[,as.character(year)] <- readTable(url)[,as.character(year)]
  }
  year <- year + 1
}
# Read in and add data from 8_ - 2013
# Table33
# 2103 table 22
files <- list.files(path = dataPath, pattern = ".(xls|xlsx)$")
data1 <- read_excel(paste0(dataPath,files[1]))
data2 <- read_excel(paste0(dataPath,files[2]))

data1 <- data1[1:(length(data1$`Table 22.`)-3),]
data1 <- data1[3:length(data1$`Table 22.`),]
data1[1,1] <- "State or Territory of Residence"

data2 <- data2 %>%
  filter(!is.na(`TABLE 33.`))
data2 <- data2[1:(length(data2$`TABLE 33.`)-2),]
data2 <- data2[2:length(data2$`TABLE 33.`),]
data2[1,1] <- data1[1,1]

colnames(data1) <- as.character(unlist(data1[1,]))
data1 <- data1[-1, ]
data1 <- data1 %>%
  select(-c("2012","2013"))

colnames(data2) <- as.character(unlist(data2[1,]))
data2 <- data2[-1, ]
data2 <- data2 %>%
  select(-c("2004"))

# Convert data types to numeric to match with data1
colsNum <- colnames(data2)
colsNum <- colsNum[2:length(colsNum)]
data2[colsNum] <- sapply(data2[colsNum],as.numeric)
colsNum <- colnames(immigrants)
colsNum <- colsNum[2:length(colsNum)]
immigrants[colsNum] <- sapply(immigrants[colsNum],function(x) gsub(",","",x))
immigrants[colsNum] <- sapply(immigrants[colsNum],as.numeric)

immigrants <- immigrants %>%
      left_join(data1, by = c("State or Territory of Residence"))
immigrants <- immigrants %>%
      left_join(data2, by = c("State or Territory of Residence"))
write.csv(immigrants, file = paste0(dataPath,"immigration.csv"))
```
 
## Read in tables
```{r eval=FALSE}
immigrants <- fread(file = paste0(dataPath,"immigration.csv"))
dataPath <- paste0(substr(dataPath, 1, nchar(dataPath)-12),"GDP/")
nominalGDP <- fread(file = paste0(dataPath,"SAGDP2.csv"))
compensationGDP <- fread(file = paste0(dataPath,"SAGDP4.csv"))
realGDP <- fread(file = paste0(dataPath,"SAGDP9.csv"))
perCapitaGDP <- fread(file = paste0(dataPath,"SAGDP10.csv"))
```

## Join two data sets
```{r}
econData <- nominalGDP %>%
  rbind(compensationGDP) %>%
  rbind(realGDP) %>%
  rbind(perCapitaGDP) %>%
  filter(nchar(TableName) != 0)
# Name GDP years
names <- colnames(econData)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    econData[,paste0(names[i])] <- as.numeric(econData[,paste0(names[i])])
    names[i] <- paste0("GDP: ",names[i])
  }
}
colnames(econData) <- names
# Name immigation years
names <- colnames(immigrants)
for (i in 1:length(names)) {
  if(!is.na(as.numeric(names[i]))) {
    names[i] <- paste0("Immigrants: ",names[i])
  }
}
colnames(immigrants) <- names
# Change total name
immigrants[1,1] <- "United States*"
compiledData <- econData %>%
  left_join(immigrants, by = c("GeoName" = "State or Territory of Residence"))
```



# Simulating the Romer Growth Model

```{r}
chooseCols <- function(x, regex) {
  cols <- grep(regex, names(x), value=TRUE)
  return(x[, cols])
}
```

```{r}
# Returns table of population in millions
createPopulationTable <- function() {
  # Divide real GDP by percapita
  real <- compiledData %>%
    filter(TableName == "SAGDP9N" & IndustryId == 1)
  per <- compiledData %>%
    filter(TableName == "SAGDP10N")
  real <- chooseCols(real, "^(GDP:|GeoName)")
  per <- chooseCols(per, "^(GDP:|GeoName)")
  pop <- real
  cols <- names(per)
  for (i in 2:length(cols)) {
    pop[,paste0(cols[i])] <- real[,paste0(cols[i])] / per[,paste0(cols[i])]
  }
  return(pop)
}
```

```{r}
# per capita GDP is tableName SAGDP10N
perCapitaGDP <- compiledData %>%
  filter(TableName == "SAGDP10N")
outputPerWorker <- chooseCols(perCapitaGDP, "^(GDP:|GeoName)")
head(outputPerWorker)
```

```{r}
# Romer growth parameters
beta <- 0.3
alpha <- 0.2
chi <- 0.04
# Population in millions
population <- createPopulationTable()
growth <- population
cols <- names(population)
colsGrowth <- gsub("GDP:","Growth:",cols)
for (i in 2:length(cols)) {
  growth[,paste0(colsGrowth[i])] <- (1 / (1 - beta)) * alpha * chi * population[,paste0(cols[i])]
}
growth <- chooseCols(growth, "^(Growth:|GeoName)")
head(growth)
```

```{r}
# Show graph of PerCapita and growth
years <- grep("[0-9]$", names(outputPerWorker), value=TRUE)
years <- as.numeric(gsub("GDP: ","",years))
totalper <- as.numeric((as.vector(outputPerWorker[1,c(2:22)])))
data <- data.frame(year = years, output = totalper)
data %>%
  ggplot(aes(x = year, y = output)) +
  geom_point()
```

























# Unsupervised Learning

Wanted to see how Real GDP, Compensation GDP, and Immigration was state by state.

```{r}
# creating a table of just states and their totals over 20 years of GDP
RealClean <-
  compiledData %>%
  filter(TableName == "SAGDP9N") %>%
  filter(GeoName != "United States*") %>%
  filter(GeoName != "United States") %>%
  filter(IndustryId == "1")

```

```{r}
# Created a table with the state and its total GDP from 1997 to 2016
GDPRealTotal <-
  RealClean %>%
  transmute(GDPRealTotal = `GDP: 1997` + `GDP: 1998` + `GDP: 1999` + `GDP: 2000` + `GDP: 2001` +
           `GDP: 2002` + `GDP: 2003` + `GDP: 2004` + `GDP: 2005` + `GDP: 2006` + `GDP: 2007` +
           `GDP: 2008` + `GDP: 2009` + `GDP: 2010` + `GDP: 2011` + `GDP: 2012` + `GDP: 2013` +
           `GDP: 2014` + `GDP: 2015` + `GDP: 2016`,
           Territory = GeoName)
```

```{r}
# creating a table of just states and their totals over 20 years of Real GDP
CompensationClean <-
  compiledData %>%
  filter(TableName == "SAGDP4N") %>%
  filter(GeoName != "United States*") %>%
  filter(GeoName != "United States") %>%
  filter(IndustryId == "1")
```

```{r}
# Created a table with the state and its compensational GDP from 1997 to 2016
GDPCompensationTotal <-
  CompensationClean %>%
  transmute(GDPCompensationTotal = `GDP: 1997` + `GDP: 1998` + `GDP: 1999` + `GDP: 2000` + `GDP: 2001` +
           `GDP: 2002` + `GDP: 2003` + `GDP: 2004` + `GDP: 2005` + `GDP: 2006` + `GDP: 2007` +
           `GDP: 2008` + `GDP: 2009` + `GDP: 2010` + `GDP: 2011` + `GDP: 2012` + `GDP: 2013` +
           `GDP: 2014` + `GDP: 2015` + `GDP: 2016`,
           Territory = GeoName)
```

```{r}
# Created a table of number of immigrants year by year per state
immigrantsNoUS <-
  immigrants %>%
  filter(`State or Territory of Residence` != "United States*")
```


```{r}
# Created a table with the total number of immigrants per state from 1997 to 2016
immigrantsTotal <-
  immigrantsNoUS %>%
  transmute(immigrantsTotal = `Immigrants: 1997` + `Immigrants: 1998` + `Immigrants: 1999` + `Immigrants: 2000` + `Immigrants: 2001` + `Immigrants: 2002` + `Immigrants: 2003` +
              `Immigrants: 2004` + `Immigrants: 2005` + `Immigrants: 2006` + `Immigrants: 2007` +
              `Immigrants: 2008` + `Immigrants: 2009` + `Immigrants: 2010` + `Immigrants: 2011` +
              `Immigrants: 2012` + `Immigrants: 2013` + `Immigrants: 2014` + `Immigrants: 2015` +
              `Immigrants: 2016`,
            Territory = `State or Territory of Residence`)
```

I am joining the Total number of immigrants, total GDP, and Compensational GDP per state into one table

```{r}
immigrantGDP <-
  left_join(immigrantsTotal, GDPRealTotal, key = "Territory")
```

```{r}
immigrantGDP <-
  left_join(immigrantGDP, GDPCompensationTotal)
```

I am removing values and making the second column the row name

```{r}
immigrantGDP <- immigrantGDP[-c(12, 41, 54, 55), ]
```

```{r}
immigrantGDPClean <- immigrantGDP[,-2]
rownames(immigrantGDPClean) <- immigrantGDP[,2]
```

```{r}
immigrantGDPClean <- immigrantGDPClean[-c(27), ]
```

Wanted to see how those three variabels affected the data overall

```{r}
GDPimmigrant_pca <- 
  prcomp(immigrantGDPClean ,scale = TRUE)  # standardize the variables
# the result is a list object
str(GDPimmigrant_pca)
```

```{r}
(-1) * GDPimmigrant_pca$rotation[, 1:2] %>% round(2)
```

```{r}
GDPimmigrant_pca$x %>%
  as.data.frame() %>%  # `ggplot2` expects a data frame object
  rownames_to_column() %>%
  ggplot(aes(x = -PC1, y = -PC2)) + 
  geom_text(aes(label = rowname), size = 3) + 
  xlab("Best Vector from PCA (approx. GDP Data)") + 
  ylab("2nd Best Vector from PCA (approx. Immigration)") + 
  ggtitle("Two-dimensional representation of GDP change based on immigration")
```

I am making a k means clustering of total GDP, compensational GDP, and immigration to see which states are most alike.

```{r}
immigrantGDP_std <-
  scale(immigrantGDPClean) %>%
  as.data.frame()
```

```{r}
set.seed(2)
immigrantGDP_kmean <-
  immigrantGDP_std %>%
  kmeans(centers = 4, nstart = 10)
```

```{r}
k_meansGroups <-
  data.frame(immigrantGDP_kmean[1]) %>%
  rownames_to_column()
```

```{r}
names(k_meansGroups) <- c("State", "cluster")
```

```{r}
StateCodes <-
  k_meansGroups %>%
  mutate(fips = fips(k_meansGroups$State))
```

```{r}
plot_usmap(data = StateCodes, values = "cluster")
```

Looking at the map we see that California is not like any other states, and then the next group only has Florida, New York, and Texas. This would make sense because the largest states would have the highest immigration counts and the largest GDP values.

# Creating visualization

I wanted to create a visualization using 3 variables.

```{r}
GraphingData <- immigrantGDP[-c(27), ]
```

```{r}
colnames(GraphingData)[colnames(GraphingData)=="Territory"] <- "GeoName"
```

```{r}
# creating a table with the states and what region they are apart of
StateAndRegion <- 
  RealClean %>%
  select(GeoName, Region)
```

```{r}
#joined the tables so now each state has the total GDP and total immigration count from 1997 to 2016
GraphingData <-
  left_join(GraphingData, StateAndRegion)

GraphingData <-
  GraphingData %>%
  mutate(immigrantsTotal = immigrantsTotal/1000,
         GDPCompensationTotal = GDPCompensationTotal/1000000)
```

```{r}
GraphingData %>%
  ggplot() + 
  geom_point(aes(x = GDPCompensationTotal, y = immigrantsTotal, colour = Region)) + 
  xlab("GDP (millions)") + 
  ylab("Number of Immigrants (Thousands)") +
  ggtitle("GDP and Immigration Totals from 1997 to 2016")
```

This graph shows us that there is one point that is an outlier and it is California. Also, this shows that there is no distinct grouping based on region over the past 20 years.

